import asyncio
import time
import logging
from typing import Dict, Any
import streamlit as st
from langchain_core.messages import BaseMessage
from graph import app_runnable

logger = logging.getLogger(__name__)

class ResearchSupervisor:
    """Clase mejorada para gesti√≥n del ciclo de investigaci√≥n"""
    def __init__(self):
        if "research_data" not in st.session_state:
            st.session_state.research_data = {
                'executions': [],
                'current_cycle': 0,
                'max_cycles': 10  # Aumentamos el l√≠mite de ciclos
            }
        
        self.tools: Dict[str, Dict[str, Any]] = {}
        self._cancelled = False

    def cancel_research(self):
        """Maneja la cancelaci√≥n limpia de la investigaci√≥n"""
        self._cancelled = True
        logger.info("Investigaci√≥n cancelada por el usuario")
        st.toast("üõë Investigaci√≥n detenida", icon="‚èπÔ∏è")

    def update_progress(self, progress: float, message: str):
        """Actualiza la barra de progreso de forma segura"""
        try:
            if 'progress_bar' in st.session_state:
                st.session_state.progress_bar.progress(
                    min(progress, 1.0), 
                    text=message
                )
        except Exception as e:
            logger.error(f"Error actualizando progreso: {str(e)}")

async def execute_research_flow(
    messages: list, 
    placeholder: st.delta_generator.DeltaGenerator
) -> str:
    """
    Flujo principal de investigaci√≥n con manejo robusto de errores
    """
    supervisor = ResearchSupervisor()
    final_text = ""
    
    try:
        # Configuraci√≥n inicial
        if 'progress_bar' not in st.session_state:
            st.session_state.progress_bar = placeholder.progress(0, text="üöÄ Iniciando investigaci√≥n...")
        
        research_stream = app_runnable.astream_events(
            {"messages": messages}, 
            version="v2",
            config={"recursion_limit": 20}  # Reducimos la recursi√≥n
        )
        
        async for event in research_stream:
            if supervisor._cancelled:
                raise asyncio.CancelledError()
            
            event_type = event["event"]
            
            # Manejo de ciclo de investigaci√≥n completo
            if event_type == "on_chain_start" and event["name"] == "planning":
                st.session_state.research_data['current_cycle'] += 1
                logger.debug(f"Ciclo de investigaci√≥n #{st.session_state.research_data['current_cycle']}")
                
                if st.session_state.research_data['current_cycle'] > st.session_state.research_data['max_cycles']:
                    raise RuntimeError("üî¨ L√≠mite m√°ximo de ciclos alcanzado. Revisa los par√°metros de b√∫squeda.")
            
            # Actualizaci√≥n de progreso din√°mico
            progress_weights = {
                "on_tool_start": 0.1,
                "on_tool_end": 0.2,
                "on_chat_model_stream": 0.05
            }
            
            current_progress = min(
                st.session_state.progress_bar.value + progress_weights.get(event_type, 0),
                0.95
            )
            supervisor.update_progress(current_progress, "üîç Analizando informaci√≥n...")
            
            # Procesamiento de eventos
            if event_type == "on_chat_model_stream":
                final_text += event["data"]["chunk"].content
                placeholder.markdown(f"```markdown\n{final_text}\n```")
            
            elif event_type == "on_tool_start":
                tool_data = {
                    'id': event["run_id"][:8],
                    'name': event["name"],
                    'input': event["data"].get("input", {}),
                    'start_time': time.time()
                }
                
                with placeholder.container():
                    cols = st.columns([1, 3])
                    cols[0].subheader(f"üõ†Ô∏è {tool_data['name']}")
                    cols[0].caption(f"ID: `{tool_data['id']}`")
                    with cols[1].expander("‚öôÔ∏è Detalles de ejecuci√≥n", expanded=True):
                        st.json(tool_data['input'], expanded=False)
                
                st.session_state.research_data['executions'].append(tool_data)
                st.toast(f"Iniciando: {tool_data['name']}", icon="‚ö°")

            elif event_type == "on_tool_end":
                output = event["data"].get("output", {})
                error = event["data"].get("error")
                
                with placeholder.container():
                    if error:
                        st.error(f"‚ùå Error en herramienta:\n```\n{str(error)[:500]}\n```")
                    else:
                        st.success(f"‚úÖ Resultado obtenido")
                        st.json(output, expanded=False)

    except asyncio.CancelledError:
        logger.warning("Investigaci√≥n cancelada por el usuario")
        placeholder.warning("‚èπÔ∏è Investigaci√≥n detenida a petici√≥n del usuario")
        return "Operaci√≥n cancelada"
    
    except RuntimeError as e:
        logger.error(f"L√≠mite de ciclos alcanzado: {str(e)}")
        placeholder.error(f"‚ö†Ô∏è {str(e)}")
        return "L√≠mite m√°ximo de iteraciones alcanzado"
    
    except Exception as e:
        logger.error(f"Error cr√≠tico: {str(e)}", exc_info=True)
        placeholder.error(f"üö® Error inesperado: {str(e)}")
        return "Error en el proceso"
    
    finally:
        # Limpieza final segura
        try:
            supervisor.update_progress(1.0, "üèÅ Proceso completado")
            await asyncio.sleep(0.5)
            if 'progress_bar' in st.session_state:
                st.session_state.progress_bar.empty()
                del st.session_state.progress_bar
        except Exception as e:
            logger.error(f"Error en limpieza: {str(e)}")
    
    return final_text